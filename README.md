# ZigWheels Dealer Scraper

Automated web scraper for extracting car dealer data from ZigWheels.com across 1,580+ Indian cities.

**Status**: âœ… Production Ready | **Tested**: BMW (2 dealers in Hyderabad, 4 in Chennai)

---

## ğŸ“‹ Project Overview

### What It Does
Scrapes dealer information (name, address, phone, email) for car brands across all Indian cities and exports to Excel.

### Why This Approach
- **Not API-based**: No public dealer API available on ZigWheels
- **Browser automation**: Uses Playwright to navigate and extract HTML
- **City discovery**: Automatically fetches 1,580+ cities from ZigWheels city JSON API
- **Efficient**: Rate-limited to avoid detection, configurable delays

---

## ğŸ”§ Architecture & Tech Stack

### Core Technology Stack

| Layer | Technology | Purpose |
|-------|-----------|---------|
| **Browser Automation** | Playwright | Navigate URLs, render JavaScript, extract HTML |
| **Programming Language** | Python 3.8+ | Main codebase with async/await support |
| **Data Processing** | Pandas | Handle dealer lists, data transformation |
| **Export** | Openpyxl | Create Excel (.xlsx) files with formatting |
| **HTTP Client** | httpx | Async HTTP requests for city JSON API |
| **Configuration** | JSON | User-friendly configuration files |
| **Logging** | Python logging | Track execution, debug issues |
| **Data Validation** | Pydantic | Validate dealer data models |

### Project Architecture

```
Config (JSON)
    â†“
main.py (Entry Point)
    â†“
ZigWheelsProductionScraper (Orchestrator)
    â”œâ”€â†’ CityDiscoverer
    â”‚   â””â”€â†’ Fetch 1,580 cities from API
    â”‚       Save to: output/cities_*.json
    â”‚
    â”œâ”€â†’ DealerAPIFetcher  
    â”‚   â””â”€â†’ Navigate to /dealers/{brand}/{city}
    â”‚       Extract dealer cards from HTML
    â”‚
    â”œâ”€â†’ DealerExtractor
    â”‚   â””â”€â†’ Parse HTML structure
    â”‚       Extract: name, address, phone, email
    â”‚
    â””â”€â†’ DataSaver
        â””â”€â†’ Convert to DataFrame
            Export to Excel
            
Output: output/zigwheels_dealers_*.xlsx
```

---

## ğŸ” How It Works

### Step 1: City Discovery
```
Endpoint: https://www.zigcdn.com/js/city_json.js?version=147.7
Method:   HTTP GET (async with httpx)
Returns:  JSON array of 1,580+ city objects
Extract:  City names only
Store:    Local cache (output/cities_*.json)
```

### Step 2: URL Construction
```
Pattern: https://www.zigwheels.com/dealers/{brand}/{city}

Examples:
  - /dealers/bmw/hyderabad
  - /dealers/maruti-suzuki/mumbai
  - /dealers/audi/bangalore
```

### Step 3: Page Navigation & Extraction
```
For each URL:
  1. Use Playwright to open page in browser
  2. Wait for page to load (domcontentloaded)
  3. Execute JavaScript to find dealer cards
  4. Target: HTML divs with class *="deal-crd"
  5. Extract from each card:
     - Name: <h3> tag
     - Address: First <p> tag
     - Phone: <a href="tel:"> link
     - Email: Regex pattern match
  6. Deduplicate by dealer name
  7. Store in memory
```

### Step 4: Data Conversion & Export
```
1. Convert raw dealer dicts to DealerData models
2. Validate required fields
3. Create Pandas DataFrame
4. Export to Excel with:
   - Proper column names
   - Formatted columns
   - Timestamp in filename
   
Output Columns:
  - vehicle_type, brand, location
  - dealer_name, address, phone, email
  - city, state, pincode
  - scraped_at (timestamp)
```

---

## ğŸ“Š Data Flow

```
User Config
    â†“
Load Brands & Cities
    â†“
Fetch 1,580 Cities (cached locally)
    â†“
For Each Brand:
    â”œâ”€ For Each City:
    â”‚   â”œâ”€ Open /dealers/{brand}/{city}
    â”‚   â”œâ”€ Wait for page load
    â”‚   â”œâ”€ Extract dealer cards
    â”‚   â”œâ”€ Parse: name, address, phone, email
    â”‚   â”œâ”€ Deduplicate
    â”‚   â””â”€ Store in list
    â””â”€ Convert to DealerData models
        â”œâ”€ Validate data
        â””â”€ Add to DataFrame
    
All Brands Complete
    â†“
Save to Excel (output/zigwheels_dealers_*.xlsx)
    â†“
Done âœ“
```

---

## ğŸš€ Quick Start

### 1. Install (2 minutes)
```bash
python3 -m venv venv
source venv/bin/activate  # Linux/Mac
# or venv\Scripts\activate  # Windows

pip install -r requirements.txt
playwright install
```

### 2. Configure (1 minute)
Edit `config/scraper_config.json`:
```json
{
  "vehicle_types": {
    "cars": {
      "brands": [
        {"name": "maruti-suzuki", "locations": "all"}
      ]
    }
  },
  "headless": true,
  "timeout": 15000,
  "natural_delays": {
    "between_cities": [1, 3],
    "between_brands": [3, 8]
  }
}
```

### 3. Run (varies by config)
```bash
python3 main.py
```

**Output**: `output/zigwheels_dealers_YYYYMMDD_HHMMSS.xlsx`

---

## ğŸ“‹ Configuration Options

### Basic Options

| Option | Type | Default | Description |
|--------|------|---------|-------------|
| `headless` | bool | true | Run without browser UI |
| `timeout` | int | 15000 | Page load timeout (ms) |
| `validate_data` | bool | false | Skip invalid dealers |
| `output_format` | string | excel | excel, csv, or json |

### Rate Limiting

```json
"natural_delays": {
  "between_cities": [1, 3],      // 1-3 seconds
  "between_brands": [3, 8],      // 3-8 seconds
  "after_page_load": [0.5, 1.5]  // Page render delay
}
```

### Brand & Location Configuration

**All cities:**
```json
{"name": "maruti-suzuki", "locations": "all"}
```

**Specific cities:**
```json
{
  "name": "hyundai",
  "locations": ["Mumbai", "Delhi", "Bangalore"]
}
```

**Multiple brands:**
```json
"brands": [
  {"name": "bmw", "locations": "all"},
  {"name": "audi", "locations": "all"},
  {"name": "mercedes-benz", "locations": "all"}
]
```

See `config/examples.json` for 7 ready-to-use configurations.

---

## ğŸ”§ Supported Brands

**Budget**: maruti-suzuki, hyundai, tata, mahindra, ford  
**Premium**: bmw, audi, mercedes-benz, skoda, volkswagen  
**Luxury**: porsche, jaguar, bentley, lamborghini, ferrari  
**Electric**: tesla, byd  
**Other**: jeep, renault, kia, citroen, mg-motor, volvo

---

## ğŸ“Š Output Format

**File**: `output/zigwheels_dealers_YYYYMMDD_HHMMSS.xlsx`

**Columns**:
```
vehicle_type    â†’ "cars"
brand           â†’ "bmw", "maruti-suzuki", etc.
location        â†’ City name
dealer_name     â†’ Dealer name
address         â†’ Full address
phone           â†’ Phone number
email           â†’ Email address
city            â†’ Parsed from address
state           â†’ Parsed from address
pincode         â†’ Parsed from address
scraped_at      â†’ Timestamp
source_url      â†’ Original page URL
```

**Example Row**:
```
| cars | bmw | Hyderabad | Kun Motoren Pvt Ltd | 6-3-569, Khairatabad... | 9581012222 | info@... |
```

---

## âš¡ Performance

### Time Estimates

| Scenario | Cities | Time | Notes |
|----------|--------|------|-------|
| 1 brand, all cities | 1,580 | 40-80 min | Depends on delays |
| 1 brand, 10 cities | 10 | ~10 min | Quick test |
| Test (BMW 2 cities) | 2 | <1 min | Verification |
| 3 brands, all cities | 1,580 | 120+ min | Sequential |

### Optimization

- **City caching**: Second run uses cached cities (2 min saved)
- **Rate limiting**: 1-3s between cities prevents blocking
- **Headless mode**: 10-15% faster than visible browser

---

## âœ… Features Implemented

### Core Scraping
- âœ“ Multi-city support (1,580+ cities)
- âœ“ Multi-brand support (configurable)
- âœ“ Flexible city selection (all or custom list)
- âœ“ Browser-based page navigation
- âœ“ JavaScript rendering support

### Data Extraction
- âœ“ Dealer name from HTML h3 tags
- âœ“ Address from paragraphs (p tags)
- âœ“ Phone numbers from tel: links
- âœ“ Email via regex pattern matching
- âœ“ Automatic deduplication
- âœ“ Data validation

### Export & Storage
- âœ“ Excel (.xlsx) export
- âœ“ CSV export support
- âœ“ JSON export support
- âœ“ Timestamp in filenames
- âœ“ Properly formatted columns

### Safety & Ethics
- âœ“ Random delays between requests
- âœ“ Configurable rate limiting
- âœ“ Headless operation
- âœ“ Respectful scraping (1-3s per city)
- âœ“ No API abuse

### Error Handling
- âœ“ Retry logic (exponential backoff)
- âœ“ Graceful failure handling
- âœ“ Detailed logging
- âœ“ Failed scrapes saved to file

---

## ğŸ› Troubleshooting

### No Dealers Found
```
1. Verify brand name is correct:
   - Use exact slug from ZigWheels URL
   - Example: "maruti-suzuki" (with hyphen)
   
2. Try a single city first:
   "locations": ["Mumbai"]
   
3. Check logs:
   tail logs/scraper_*.log
```

### Slow Performance
```
1. Reduce delays in config:
   "between_cities": [0.5, 1]
   
2. Use specific cities instead of "all":
   "locations": ["Mumbai", "Delhi"]
   
3. Check internet connection
```

### Browser Issues
```
1. Set headless to false to see what's happening:
   "headless": false
   
2. Reinstall Playwright:
   playwright install --with-deps
   
3. Check system has enough RAM (2GB minimum)
```

### Page Timeout
```
1. Increase timeout in config:
   "timeout": 20000
   
2. Check if ZigWheels website is accessible
   
3. Try with fewer delays (site might be slow)
```

---

## ğŸ“š Documentation

- **START_HERE.md** - 3-step quick start guide
- **QUICKSTART.md** - Detailed setup instructions
- **config/examples.json** - 7 example configurations
- **test_quick.py** - Quick validation tests

---

## ğŸ§ª Testing

Run quick tests to verify setup:
```bash
python3 test_quick.py
```

Expected output:
```
âœ“ Found 1580 cities
âœ“ Found 2 dealers in Hyderabad
âœ“ Found 4 dealers in Chennai
âœ“ Total: 6 dealers
âœ… ALL TESTS PASSED
```

---

## ğŸ“ Project Structure

```
zigwheels-scraper/
â”œâ”€â”€ main.py                      # Entry point
â”œâ”€â”€ requirements.txt             # Dependencies
â”œâ”€â”€ test_quick.py                # Tests
â”œâ”€â”€ README.md                    # This file
â”œâ”€â”€ START_HERE.md                # Quick start
â”œâ”€â”€ QUICKSTART.md                # Detailed guide
â”‚
â”œâ”€â”€ config/
â”‚   â”œâ”€â”€ scraper_config.json      # Main config (edit this)
â”‚   â””â”€â”€ examples.json            # 7 example configs
â”‚
â”œâ”€â”€ src/scraper/
â”‚   â”œâ”€â”€ core/
â”‚   â”‚   â”œâ”€â”€ scraper.py           # Main orchestrator
â”‚   â”‚   â”œâ”€â”€ city_discoverer.py   # Fetch cities
â”‚   â”‚   â”œâ”€â”€ dealer_api_fetcher.py# Navigate & fetch
â”‚   â”‚   â”œâ”€â”€ browser.py           # Browser management
â”‚   â”‚   â””â”€â”€ config.py            # Config loader
â”‚   â”‚
â”‚   â”œâ”€â”€ models/
â”‚   â”‚   â”œâ”€â”€ dealer.py            # DealerData model
â”‚   â”‚   â””â”€â”€ enums.py             # Enums
â”‚   â”‚
â”‚   â”œâ”€â”€ storage/
â”‚   â”‚   â””â”€â”€ data_saver.py        # Excel/CSV export
â”‚   â”‚
â”‚   â”œâ”€â”€ extractors/
â”‚   â”‚   â””â”€â”€ dealer_extractor.py  # HTML parsing
â”‚   â”‚
â”‚   â”œâ”€â”€ exceptions/
â”‚   â”‚   â””â”€â”€ custom_exceptions.py # Custom errors
â”‚   â”‚
â”‚   â””â”€â”€ utils/
â”‚       â”œâ”€â”€ logger.py            # Logging
â”‚       â”œâ”€â”€ helpers.py           # Utilities
â”‚       â””â”€â”€ validators.py        # Validation
â”‚
â”œâ”€â”€ output/                      # Generated files
â”‚   â”œâ”€â”€ cities_*.json            # Cached cities
â”‚   â”œâ”€â”€ zigwheels_dealers_*.xlsx # Excel output
â”‚   â””â”€â”€ failed_scrapes_*.json    # Failed records
â”‚
â””â”€â”€ logs/                        # Execution logs
    â””â”€â”€ scraper_*.log
```

---

## ğŸ” Security & Ethics

- âœ“ Rate limiting prevents server overload
- âœ“ Random delays simulate human behavior
- âœ“ Respects website structure and robots.txt
- âœ“ For business intelligence only
- âœ“ Not for spam, resale, or unauthorized use

---

## ğŸ“ˆ Future Enhancements

Planned features for v2:
- Smart city caching (skip cities without dealers)
- Batch brand discovery (find all brands in city)
- Database export (PostgreSQL, MongoDB)
- Scheduled scraping jobs
- Web UI for configuration
- Multi-threaded city processing

---

## ğŸ“ Support

If issues occur:
1. Check `logs/scraper_*.log` for error details
2. Review this README for configuration options
3. Try with `"headless": false` to debug
4. Verify brand slug is correct
5. Test with single city first

---

## ğŸ“ License

Proprietary - For authorized use only.

---

**Last Updated**: November 29, 2025  
**Version**: 3.0 (Production Ready)  
**Status**: âœ… All Tests Passing
